contains("weight") |
contains("news_canada_") | contains("news_trust_") | contains("Q118_")
) %>%
select(-c("news_canada_29", "news_trust_28", "Q118_28"))
colnames(source_perception) <-
c(
c(
"vote_2019",
"vote_2019_aggregated",
"weight"
),
paste0("familiar_", names(news_sources)),
paste0("trust_", names(trust_sources)),
paste0("perception_", names(perception_sources))
)
sources <- list()
sources[["source_info"]] <- source_info
sources[["source_trust"]] <- source_trust
sources[["source_perception"]] <- source_perception
return(sources)
}
create_familiarity_tables <- function(sources){
ource_info <<- sources[["source_info"]]
source_trust <<- sources[["source_trust"]]
source_perception <<- sources[["source_perception"]]
familiarity <- tibble(news_source = names(news_sources))
familiarity_full <-
familiarity %>% mutate(full_sample1 = map(news_source, ~ proportion_with_condition(.))) %>% unnest_wider(full_sample1)  # Full sample
colnames(familiarity_full) <- c("News Source", "Full Sample")
familiarity_gender <- familiarity %>% mutate(full_sample1 = map(
news_source,
~ proportion_with_condition(., condition_variable = "gender")
)) %>% unnest_wider(full_sample1)
colnames(familiarity_gender) <- c("News Source", paste0("Gender: ", colnames(familiarity_gender)[2 : ncol(familiarity_gender)]))
familiarity_age <- familiarity %>% mutate(full_sample1 = map(
news_source,
~ proportion_with_condition(., condition_variable = "age_group")
)) %>% unnest_wider(full_sample1)
colnames(familiarity_age) <- c("News Source", paste0("Age: ", colnames(familiarity_age)[2 : ncol(familiarity_age)]))
familiarity_region <- familiarity %>% mutate(full_sample1 = map(
news_source,
~ proportion_with_condition(., condition_variable = "region")
)) %>% unnest_wider(full_sample1)
colnames(familiarity_region) <- c("News Source", paste0("Region: ", colnames(familiarity_region)[2 : ncol(familiarity_region)]))
familiarity_vote_2019 <- familiarity %>% mutate(full_sample1 = map(
news_source,
~ proportion_with_condition(., condition_variable = "vote_2019")
)) %>% unnest_wider(full_sample1)
colnames(familiarity_vote_2019) <- c("News Source", paste0("2019 Vote: ", colnames(familiarity_vote_2019)[2 : ncol(familiarity_vote_2019)]))
familiarity_vote_2019_aggregated <- familiarity %>% mutate(full_sample1 = map(
news_source,
~ proportion_with_condition(., condition_variable = "vote_2019_aggregated")
)) %>% unnest_wider(full_sample1)
colnames(familiarity_vote_2019_aggregated) <- c("News Source", paste0("2019 Vote: ", colnames(familiarity_vote_2019_aggregated)[2 : ncol(familiarity_vote_2019_aggregated)]))
table_1_1 <- familiarity_full %>% inner_join(familiarity_gender, on = "News Source") %>% inner_join(familiarity_age, on = "News Source")
table_1_2 <- familiarity_full %>% inner_join(familiarity_region, on = "News Source")
table_1_3 <- familiarity_full %>% inner_join(familiarity_vote_2019_aggregated, on = "News Source")
familiarity_tables <- list(table_1_1, table_1_2, table_1_3)
return(familiarity_tables)
}
create_trust_tables <- function(sources){
source_info <<- sources[["source_info"]]
source_trust <<- sources[["source_trust"]]
source_perception <<- sources[["source_perception"]]
trust <- tibble(news_source = names(news_sources))
trust_full <-
trust %>% mutate(full_sample1 = map(news_source, ~ trust_proportion_with_condition(.))) %>% unnest_wider(full_sample1)  # Full sample
colnames(trust_full) <- c("News Source", "Full Sample")
trust_gender <-
trust %>% mutate(full_sample1 = map(
news_source,
~ trust_proportion_with_condition(., condition_variable = "gender")
)) %>% unnest_wider(full_sample1)
colnames(trust_gender) <- c("News Source", paste0("Gender: ", colnames(trust_gender)[2 : ncol(trust_gender)]))
trust_age <-
trust %>% mutate(full_sample1 = map(
news_source,
~ trust_proportion_with_condition(., condition_variable = "age_group")
)) %>% unnest_wider(full_sample1)
colnames(trust_age) <- c("News Source", paste0("Age: ", colnames(trust_age)[2 : ncol(trust_age)]))
trust_region <-
trust %>% mutate(full_sample1 = map(
news_source,
~ trust_proportion_with_condition(., condition_variable = "region")
)) %>% unnest_wider(full_sample1)
colnames(trust_region) <- c("News Source", paste0("Region: ", colnames(trust_region)[2 : ncol(trust_region)]))
trust_vote_2019 <-
trust %>% mutate(full_sample1 = map(
news_source,
~ trust_proportion_with_condition(., condition_variable = "vote_2019")
)) %>% unnest_wider(full_sample1)
colnames(trust_vote_2019) <- c("News Source", paste0("2019 Vote: ", colnames(trust_vote_2019)[2 : ncol(trust_vote_2019)]))
trust_vote_2019_aggregated <-
trust %>% mutate(full_sample1 = map(
news_source,
~ trust_proportion_with_condition(., condition_variable = "vote_2019_aggregated")
)) %>% unnest_wider(full_sample1)
colnames(trust_vote_2019_aggregated) <- c("News Source", paste0("2019 Vote: ", colnames(trust_vote_2019_aggregated)[2 : ncol(trust_vote_2019_aggregated)]))
table_2_1 <- trust_full %>% inner_join(trust_gender, on = "News Source") %>% inner_join(trust_age, on = "News Source")
table_2_2 <- trust_full %>% inner_join(trust_region, on = "News Source")
table_2_3 <- trust_full %>% inner_join(trust_vote_2019_aggregated, on = "News Source")
trust_tables <- list(table_2_1, table_2_2, table_2_3)
return(trust_tables)
}
print_all_tables <-function(familiarity_tables, trust_tables){
knitr::kable(familiarity_tables[[1]], digits = 2) %>% print()
knitr::kable(familiarity_tables[[2]], digits = 2) %>% print()
knitr::kable(familiarity_tables[[3]], digits = 2) %>% print()
knitr::kable(trust_tables[[1]], digits = 2) %>% print()
knitr::kable(trust_tables[[2]], digits = 2) %>% print()
knitr::kable(trust_tables[[3]], digits = 2) %>% print()
for (source in names(news_sources)) {
perception_table <- create_preception_table(source)
cat(paste0("News source: ", source), sep = "\n")
print(knitr::kable(perception_table, digits = 2))
cat("\n")
}
}
create_cross_tabs <- function(survey){
sources <- create_sources(survey)
familiarity_tables <- create_familiarity_tables(sources)
trust_tables <- create_trust_tables(sources)
print_all_tables(familiarity_tables, trust_tables)
}
create_cross_tabs(survey)
View(create_cross_tabs)
colnames(familiarity_gender)
col_order_gender <- c("News Source", "Gender: Male", "Gender: Female", "Gender: Other gender")
familiarity_gender <- familiarity_gender[, col_order]
familiarity_gender <- familiarity_gender[, col_order_gender]
familiarity_gender
colnames(familiarity_age)
col_order_age <- c("News Source", "Age: 18-34", "Age: 35-49", "Age: 50-64", "Age: 65+")
familiarity_age <- familiarity_age[, col_order_age]
View(familiarity_age)
colnames(familiarity_region)
col_order_region <- c("News Source", "Region: Prairies", "Region: Atlantic", "Region: BC", "Region: Alberta", "Region: Quebec", "Region: Ontario")
familiarity_region <- familiarity_region[, col_order_region]
View(familiarity_region)
colnames(familiarity_vote_2019_aggregated)
col_order_vote_2019_aggregated <- c("News Source", "2019 Vote: Liberal", "2019 Vote: Conservative", "2019 Vote: NDP or Green", "2019 Vote: Bloc Quebecois")
familiarity_vote_2019_aggregated <- familiarity_vote_2019_aggregated[, col_order_vote_2019_aggregated]
View(familiarity_vote_2019_aggregated)
trust_gender <- trust_gender[, col_order_gender]
trust <- tibble(news_source = names(news_sources))
trust_full <-
trust %>% mutate(full_sample1 = map(news_source, ~ trust_proportion_with_condition(.))) %>% unnest_wider(full_sample1)  # Full sample
colnames(trust_full) <- c("News Source", "Full Sample")
trust_gender <-
trust %>% mutate(full_sample1 = map(
news_source,
~ trust_proportion_with_condition(., condition_variable = "gender")
)) %>% unnest_wider(full_sample1)
colnames(trust_gender) <- c("News Source", paste0("Gender: ", colnames(trust_gender)[2 : ncol(trust_gender)]))
trust_gender <- trust_gender[, col_order_gender]
trust_age <-
trust %>% mutate(full_sample1 = map(
news_source,
~ trust_proportion_with_condition(., condition_variable = "age_group")
)) %>% unnest_wider(full_sample1)
colnames(trust_age) <- c("News Source", paste0("Age: ", colnames(trust_age)[2 : ncol(trust_age)]))
trust_age <- trust_age[, col_order_age]
trust_region <-
trust %>% mutate(full_sample1 = map(
news_source,
~ trust_proportion_with_condition(., condition_variable = "region")
)) %>% unnest_wider(full_sample1)
colnames(trust_region) <- c("News Source", paste0("Region: ", colnames(trust_region)[2 : ncol(trust_region)]))
trust_region <- trust_region[, col_order_region]
trust_vote_2019_aggregated <-
trust %>% mutate(full_sample1 = map(
news_source,
~ trust_proportion_with_condition(., condition_variable = "vote_2019_aggregated")
)) %>% unnest_wider(full_sample1)
colnames(trust_vote_2019_aggregated) <- c("News Source", paste0("2019 Vote: ", colnames(trust_vote_2019_aggregated)[2 : ncol(trust_vote_2019_aggregated)]))
trust_vote_2019_aggregated <- trust_vote_2019_aggregated[, col_order_vote_2019_aggregated]
table_2_1 <- trust_full %>% inner_join(trust_gender, on = "News Source") %>% inner_join(trust_age, on = "News Source")
table_2_2 <- trust_full %>% inner_join(trust_region, on = "News Source")
table_2_3 <- trust_full %>% inner_join(trust_vote_2019_aggregated, on = "News Source")
library(tidyverse)
cars
cars_updated <- cars %>%
tibble() %>%
mutate(speedperdict = speed / dist)
View(cars_updated)
cars_updated
cars_updated <- cars_updated %>%
rowwise() %>%
mutate(speeddistaverage = mean(speed, dist)) %>%
ungroup()
View(cars_updated)
update.packages()
update.packages(ask = FALSE)
source("Career/r-challenge-egcjap/R_challenge_1.R")
View(exchange_rates)
# Test
payments <- extract_payments_info(fb_inv_payment_json, exchange_rates)
lapply(c("tidyverse", "jsonlite", "lubridate"), library, character.only = TRUE)
#' Extract payment information from jsons
#'
#' @param fb_inv_payment_json A dataframe
#' The dataframe should have an element named "response", which in turn has an element named "result".
#' The "result" element should in turn have an element named "payments".
#' This function extracts information from "payments".
#'
#' @param exchange_rates A dataframe
#' The dataframe should have one row, which stores the exchange rates.
#' The column names of the dataframe are names of foreign currencies that should be converted to US Dollars.
#'
#' @return A dataframe
#' Transformed "payments" data for use.
#'
#' @export
#'
#' @examples
#' extract_payments_info(fb_inv_payment_json, exchange_rates)
extract_payments_info <-
function(fb_inv_payment_json = fb_inv_payment_json,
exchange_rates = exchange_rates) {
## Extract dataframe
payments <-
fb_inv_payment_json[["response"]][["result"]][["payments"]][[1]]
## Column transformations
### Unnest the amount column
payments <- payments %>%
unnest(cols = c(amount))
### Add a month to the date column
payments <- payments %>%
mutate(date = as_date(date, format = "%Y-%m-%d"),
date = add_with_rollback(date, months(1)))
### Convert amount.amount to USD
#### Reshape the exchange_rates table
exchange_rates <- exchange_rates %>%
t() %>%
as.data.frame() %>%
rownames_to_column()
names(exchange_rates) <- c("currency", "exchange_rate")
#### Calculate the USD values of amount.amount
# Note: there seems to be a mistake in how currencies are converted in `fb_inv_payment_processeds`.
# Non-USD values should be divided by the exchange rates to get USD values.
payments <- payments %>%
left_join(exchange_rates, by = c("code" = "currency")) %>%
mutate(
amount = as.numeric(amount),
amount = case_when(code == "USD" ~ amount,
TRUE ~ amount / exchange_rate),
code = "USD"
) %>%
mutate(amount = round(amount, 0)) %>%
select(-exchange_rate)
### Replace empty strings with NAs
payments <- payments %>%
mutate(across(where(is.character), ~ na_if(., "")))
### Replace columns with all NA values
# This does not seem to be a goodw practice in production since we will not be sure which columns will happen to have all NA values
payments <- payments %>%
select(where( ~ !all(is.na(.x))))
### Preflix call columns with "fb_"
payments <- rename_with(payments, ~ paste0("fb_", .x))
return(payments)
}
source("Career/r-challenge-egcjap/R_challenge_1.R")
# Test
payments <- extract_payments_info(fb_inv_payment_json, exchange_rates)
all_equal(fb_inv_payment_processed, payments)
View(payments)
View(fb_inv_payment_processed)
rownames(payments)
rownames(fb_inv_payment_processed)
lapply(c("tidyverse", "stringi"), library, character.only = TRUE)
# Part 1:
two_source_coverages <- function(coverage_data = R_challenge_2_data){
provider_comb_coverage <- coverage_data %>%
full_join(coverage_data, by = "data_hash") %>% # Get all combinations of two providers
filter(provider.x != provider.y) %>% # We want the two providers to be different
mutate(found = found.x | found.y) %>% # A data point is covered when at least one data provider has the data
select(data_hash, provider.x, provider.y, found) %>% # Get the columns we need
group_by(provider.x, provider.y) %>% # Calculate the number of covered data points per combination
summarise(coverage = sum(found, na.rm = TRUE)) %>%
ungroup() %>%
arrange(-coverage) %>% # Re-arrange the counts in descending order
# Here, for each pair of data sources, there are two rows corresponding to it. For example, for source_1 and source_2, we have:
# provider.x == source_1 and provider.y == source_2
# provider.x == source_2 and provider.y == source_1
# We only keep one of these duplicates
filter(stringi::stri_cmp(provider.x, provider.y) == 1)
return(provider_comb_coverage)
}
## Test
R_challenge_2_data <- read_csv("Career/r-challenge-egcjap/R_challenge_2_data.csv")
coverages <- two_source_coverages(coverage_data = R_challenge_2_data)
View(coverages)
# Part 1:
two_source_coverages <- function(coverage_data = R_challenge_2_data){
provider_comb_coverage <- coverage_data %>%
full_join(coverage_data, by = "data_hash") %>% # Get all combinations of two providers
filter(provider.x != provider.y) %>% # We want the two providers to be different
mutate(found = found.x | found.y) %>% # A data point is covered when at least one data provider has the data
select(data_hash, provider.x, provider.y, found) %>% # Get the columns we need
group_by(provider.x, provider.y) %>% # Calculate the number of covered data points per combination
summarise(coverage = sum(found, na.rm = TRUE), .groups = 'drop') %>%
ungroup() %>%
arrange(-coverage) %>% # Re-arrange the counts in descending order
# Here, for each pair of data sources, there are two rows corresponding to it. For example, for source_1 and source_2, we have:
# provider.x == source_1 and provider.y == source_2
# provider.x == source_2 and provider.y == source_1
# We only keep one of these duplicates
filter(stringi::stri_cmp(provider.x, provider.y) == 1)
return(provider_comb_coverage)
}
## Test
R_challenge_2_data <- read_csv("Career/r-challenge-egcjap/R_challenge_2_data.csv")
coverages <- two_source_coverages(coverage_data = R_challenge_2_data)
R_challenge_2_data %>%
pivot_wider(names_from = "provider", values_from = "found") %>%
filter(source_11 == TRUE | source_7 == TRUE)
R_challenge_2_data %>%
pivot_wider(names_from = "provider", values_from = "found") %>%
filter(source_11 == TRUE | source_7 == TRUE) %>%
nrow()
## Test
unique_data_points <-
get_unique_data_points(coverage_data = R_challenge_2_data)
get_unique_data_points <-
function(coverage_data = R_challenge_2_data) {
unique_data_points <- R_challenge_2_data %>%
pivot_wider(names_from = "provider", values_from = "found") %>%
rowwise() %>% # We want to sum up the values from a range of columns for each row
mutate(n_source = sum(c_across(-data_hash), na.rm = TRUE)) %>% # Important to set na.rm = TRUE
filter(n_source == 1) %>% # Find data points that are only covered by one source
select(-n_source) %>%
pivot_longer(cols = -data_hash) %>%
filter(value == TRUE) %>%
select(data_hash, name) %>%
rename(source = name)
return(unique_data_points)
}
## Test
unique_data_points <-
get_unique_data_points(coverage_data = R_challenge_2_data)
View(unique_data_points)
R_challenge_2_data %>%
pivot_wider(names_from = "provider", values_from = "found")
R_challenge_2_data %>%
pivot_wider(names_from = "provider", values_from = "found") %>%
rowwise() %>%
mutate(n_source = sum(-data_hash))
R_challenge_2_data %>%
pivot_wider(names_from = "provider", values_from = "found") %>%
rowwise() %>%
mutate(n_source = sum(c_across(-data_hash)))
R_challenge_2_data %>%
pivot_wider(names_from = "provider", values_from = "found") %>%
rowwise() %>%
mutate(n_source = sum(c_across(-data_hash), na.rm = TRUE)) %>%
filter(n_source == 1)
View(R_challenge_2_data)
View(coverages)
View(unique_data_points)
names(unique_data_points)
source('~/Career/r-challenge-egcjap/R_challenge_2_answer.R', echo=TRUE)
source('~/Career/r-challenge-egcjap/R_challenge_1_answer.R', echo=TRUE)
View(fb_inv_payment_processed)
View(fb_inv_payment_json)
View(fb_inv_payment_json[[3]][[1]])
View(exchange_rates)
payments$
mtcars %>%
group_by(cyl) %>%
summarise(qs = quantile(disp, c(0.25, 0.75)), prob = c(0.25, 0.75))
library(tidyverse)
mtcars %>%
group_by(cyl) %>%
summarise(qs = quantile(disp, c(0.25, 0.75)), prob = c(0.25, 0.75))
mtcars %>%
group_by(cyl) %>%
summarise(qs = quantile(disp, c(0.25, 0.75)), prob = c(0.25, 0.75), .groups = "drop")
1+1
print("fasf")
update.packages(ask = FALSE)
install.packages("tidyverse")
install.packages("devtools")
shiny::runApp('Documents/rshiny/example1/MyApp')
runApp('Documents/rshiny/example1/MyApp')
runApp('Documents/rshiny/example1/MyApp')
runApp('Documents/rshiny/example1/MyApp')
runApp('Documents/rshiny/example1/MyApp')
runApp('Documents/rshiny/example1/MyApp')
runApp('Documents/rshiny/example1/MyApp')
runApp('Documents/rshiny/example1/MyApp')
runApp('Documents/rshiny/example1/MyApp')
runApp('Documents/rshiny/example1/MyApp')
runApp('Documents/rshiny/example1/MyApp')
data <- read_csv("data/1310081701_databaseLoadingData.csv")
setwd("~/Documents/rshiny/example1/MyApp/")
data <- read_csv("data/1310081701_databaseLoadingData.csv")
View(data)
data$`Selected Sociodemographic characteristics` %>% str_subset("Highest level of eduction")
data$`Selected Sociodemographic characteristics` %>% str_subset("Highest level of education")
runApp()
runApp()
runApp()
data <- read_csv("data/1310081701_databaseLoadingData.csv")
View(data)
source("~/Documents/rshiny/example1/MyApp/create_chart.R", echo=TRUE)
data <- data %>%
filter(
`Selected Sociodemographic characteristics` %in% c(
"Total population",
"Visible minority",
"Highest level of education (ages 25 and older), post-secondary certificate/diploma or university degree"
)
) %>%
mutate(
`Selected Sociodemographic characteristics` = if_else(
`Selected Sociodemographic characteristics` == "Highest level of education (ages 25 and older), post-secondary certificate/diploma or university degree",
"Post-secondary education",
`Selected Sociodemographic characteristics`
)
) %>%
filter(`Sexual orientation` %in% c("Hetrosexual", "Lesbian or gay")) %>%
select(GEO, `Selected Sociodemographic characteristics`, VALUE) %>%
rename(Demographic = `Selected Sociodemographic characteristics`) %>%
mutate(thousands = VALUE / 1000)
runApp()
source("~/Documents/rshiny/example1/MyApp/create_chart.R", echo=TRUE)
runApp()
runApp()
setwd("~/Documents/rshiny/example1/MyApp/")
setwd("~/Documents/rshiny/example1/MyApp/")
data <- read_csv("data/1310081701_databaseLoadingData.csv")
data <- data %>%
filter(
`Selected Sociodemographic characteristics` %in% c(
"Total population",
"Visible minority",
"Highest level of education (ages 25 and older), post-secondary certificate/diploma or university degree"
)
) %>%
mutate(
`Selected Sociodemographic characteristics` = if_else(
`Selected Sociodemographic characteristics` == "Highest level of education (ages 25 and older), post-secondary certificate/diploma or university degree",
"Post-secondary education",
`Selected Sociodemographic characteristics`
)
) %>%
filter(`Sexual orientation` %in% c("Hetrosexual", "Lesbian or gay")) %>%
select(GEO, `Selected Sociodemographic characteristics`, VALUE) %>%
rename(Demographic = `Selected Sociodemographic characteristics`) %>%
mutate(thousands = VALUE / 1000)
chart_race <- data %>%
filter(Demographic %in% c("Visible minority", "Total population")) %>%
filter(!(GEO %in% c(
"Canada", "Atlantic provinces", "Territories"
))) %>%
mutate(
GEO = fct_relevel(
GEO,
"British Columbia",
"Prairie provinces",
"Ontario",
"Quebec"
),
Demographic = fct_relevel(Demographic, "Visible minority", "Total population")
) %>%
mutate() %>%
drop_na() %>%
ggplot(aes(y = GEO, x = thousands)) +
facet_grid(cols = vars(`Sexual orientation`)) +
geom_col(aes(fill = Demographic), position = position_dodge()) +
labs(title = "Lesbian and Gay Canadians") +
theme(axis.title.y = element_blank(),
legend.title = element_blank())
chart_race
data %>%
filter(Demographic %in% c("Visible minority", "Total population")) %>%
filter(!(GEO %in% c(
"Canada", "Atlantic provinces", "Territories"
))) %>%
mutate(
GEO = fct_relevel(
GEO,
"British Columbia",
"Prairie provinces",
"Ontario",
"Quebec"
),
Demographic = fct_relevel(Demographic, "Visible minority", "Total population")
) %>%
mutate() %>%
drop_na() %>%
ggplot(aes(y = GEO, x = thousands))
data %>%
filter(Demographic %in% c("Visible minority", "Total population")) %>%
filter(!(GEO %in% c(
"Canada", "Atlantic provinces", "Territories"
))) %>%
mutate(
GEO = fct_relevel(
GEO,
"British Columbia",
"Prairie provinces",
"Ontario",
"Quebec"
),
Demographic = fct_relevel(Demographic, "Visible minority", "Total population")
) %>%
mutate() %>%
drop_na()
runApp()
runApp()
runApp()
